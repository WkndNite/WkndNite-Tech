---
title: 计算层软件架构技术如何发展而来？
description: 计算层软件架构
sidebar:
    order: 2
---

计算层的软件架构技术将从挑战与历史、分布式编程模型、负载均衡、消息队列和分布式服务框架等方面进行介绍。

## 计算层的软件架构技术挑战

---

### 单机计算模式的变革

-   `单机任务` 是最初采用的计算模式
-   `升级处理器 / 并行计算 ` 提升计算能力
-   `服务器` 解决掉想脱离客户机载体的计算需求
-   `集群 / 消息队列 / 负载调度` 应对用户规模激增问题
-   `多机房 / 冗余 / 异地多活 / 降级` 应对用户规模爆炸问题

也就是说，从计算复杂性的角度来讲——我们越来越需要**高性能、高扩展、高可用的计算模式**。

### 分布式计算模式的兴起

鉴于大型应用中业务需求的爆炸式增长、技术的不断演进导致系统异构化严重以及业务与技术的沟通存在鸿沟—— **传统垂直架构改造的核心，就是要对应用进行服务化。** 而服务化改造使用的核心技术，就是分布式服务框架。

然而，在应用从集中转向分布式的过程中，依旧存在以下问题：

-   系统开发维护成本高，部署效率低，应用数量膨胀，数据库连接数持续变高。
-   代码复用难度大，导致开发、测试、维护等工作烦、难、杂。
-   难以应对敏捷持续交付的挑战。

因此，大规模系统架构的设计一般原则就是**尽可能地拆分**，以达到更好的独立扩展与伸缩、更灵活的部署、更好的隔离和容错、更高的开发效率。

-   **业务纵向拆分**：按业务进行梳理，根据业务的特性把应用拆开，不同的业务模块独立部署。
-   **业务横向拆分**：将核心的、公共的业务拆分出来，通过分布式服务框架对业务进行服务化，消费者通过标准的契约来消费这些服务。服务提供者独立打包、部署和演进，与消费者解藕。

然而，在业务拆分之后服务数增多，**服务治理问题**成为了亟待解决的问题。服务治理的目标是**有效管控服务，提升服务运行质量，防止业务服务代码架构腐化。**服务治理要解决的主要问题如下：

-   **生命周期的管理**：服务上线随意，线上服务鱼龙混杂，上线容易下线难。需要规范化上线审批、测试发布流程、下线通知等。
-   **服务容量的规划**：需要能够采集服务调用性能、时延、成功率、系统资源占用等综合性能指标，分析并识别服务容量瓶颈，合理分配服务容量（计算、数据、网络等资源）。
-   **运行时的治理**：流量陡增时的非核心业务 SLA 降级；缓存失效，数据 I/O 开销陡增导致业务失败，需要在线调大服务调用超时时间；非核心服务故障时，业务应放行并执行本地降级逻辑。
-   **服务安全的保障**：服务调用鉴权、服务调用加密、服务调用防重放、服务调用限流、服务调用熔断、服务调用降级等。

### 非功能度量指标

-   **性能**：系统的性能指标包括 CPU 速度（MIPS）、RT 响应时间、吞吐量（MIPS / TFLOPS / TPS / QPS）、网络带宽（MbPS）、并发数、网络延时 等。
-   **可用性**：系统的可用性指标包括 MTBF、MTTR、MTTF、SLA、SLI、SLO、SLR 等。
-   **扩展性**：系统的扩展性指标包括水平扩展、垂直扩展、弹性扩展、伸缩性、容量规划、负载均衡、分布式存储、分布式计算等。

:::tip[相关概念]
TPS（Transactions Per Second）是指每秒钟系统处理的事务数，而 QPS（Queries Per Second）是指每秒钟系统处理的查询数。在数据库中，TPS 通常指的是事务数，而 QPS 通常指的是查询数。

MTTF（Mean Time To Failure）是指平均故障时间，MTTR（Mean Time To Repair）是指平均修复时间，MTBF（Mean Time Between Failures）是指平均故障间隔时间。

其中关系可以表示成：MTBF = MTTF + MTTR。系统可用性 = MTBF / (MTBF + MTTR)。在实际应用中，有些概念会将 MTBF 计算过程中再加一个 MTTD（Mean Time To Detect）。

这么看还是一团乱麻的，可以参考 [这篇文章](https://blog.csdn.net/yunhua_lee/article/details/121674703)。
:::

## 分布式编程模型

---

### 分布式编程模式

“摩尔定律”，即计算机硬件性能每隔 18 个月就会翻一番，而价格却会降低一半。这个定律在 2004 年左右开始失效，因为 CPU 的频率已经达到物理极限，无法再通过提高频率来提升性能。

因此，计算机硬件性能的提升开始转向多核处理器和并行计算。

谷歌公司的 **MapReduce** 和 **Hadoop** 等分布式计算框架应运而生，它们通过将计算任务分发到多个处理器上并行执行，从而实现了性能的大幅提升。

> 在 MapReduce 出现之前，已经有了 MPI 这样的并行计算框架。然而，MPI 的编程模型相对复杂，需要程序员手动管理并行计算中的数据分发和通信，这给程序员带来了很大的负担。

下面表格展示了 MapReduce 和 MPI 的主要区别：
| 特性 | MapReduce | MPI |
| ------------ | --------------------------- | ----------------------------- |
| 编程模型 | Map 和 Reduce 函数 | 点对点通信和集合操作 |
| 容错性 | 自动容错，任务失败自动重试 | 需要手动处理错误和容错 |
| 扩展性 | 自动扩展，支持大规模集群 | 需要手动管理节点和任务分配 |
| 编程难度 | 简单，适合大数据处理 | 复杂，需要手动管理并行计算 |
| 适用场景 | 批处理、非实时、数据密集型 | 实时、细粒度计算、计算密集型 |
| 硬件/价格/扩展性 | 刀片服务器、高速网、SAN，价格贵，扩展性差 | 普通 PC 机，便宜，扩展性好 |

### 分布式计算集群

分布式文件系统把文件分布存储到多个计算机节点上，成千上万的计算机节点构成计算机集群——与之前使用多个处理器和专用高级硬件的并行化处理装置不同的是，目前的分布式文件系统所采用的计算机集群，都是由普通硬件构成的，这就大大降低了硬件上的开销。

### 分布式文件系统的结构

分布式文件系统在物理结构上是由计算机集群中的多个节点构成的，这些节点分为两类——一类叫**主节点**，另一类叫**从节点**或者**数据节点**。

### MapReduce 模型

#### 简介

MapReduce 将复杂的、运行于大规模集群上的并行计算过程高度抽象成了两个函数——Map 和 Reduce。

-   MapReduce 模型的核心思想是**分而治之**，即将一个大任务分解成多个小的任务，然后将这些小的任务分发给多个计算节点并行处理，最后将各个节点的处理结果汇总起来得到最终结果。
-   MapReduce 设计的一个理念就是**将计算向数据迁移**，而不是将数据向计算迁移。也就是说，MapReduce 模型会将数据分发到各个计算节点上，而不是将计算任务分发到各个计算节点上。这样做的好处是可以减少网络通信的开销，提高计算效率。
-   MapReduce 框架采用了 **Master/Slave** 架构，由一个 Master 节点和多个 Slave 节点组成。Master 节点运行 JobTracker，负责调度和管理各个 Slave 节点上的 TaskTracker。Slave 节点运行 TaskTracker，负责执行具体的计算任务。

:::MapReduce 和 Hadoop
MapReduce 是一种编程模型，而 Hadoop 是一个实现了 MapReduce 编程模型的分布式计算框架。Hadoop 使用 MapReduce 模型来处理大规模数据集，并将计算任务分发到多个计算节点上并行处理。Hadoop 是用 Java 编写的，但是也可以使用其他语言编写 MapReduce 程序。
:::

#### 组成部分

MapReduce 体系结构主要由四个部分组成：**Client**、**JobTracker**、**TaskTracker** 和 **Task**。

-   **Client**：用户编写的 MapReduce 程序通过 Client 提交到 JobTracker 端，用户可通过 Client 提供的一些接口查看作业运行状态。
-   **JobTracker**：JobTracker 负责资源监控和作业调度，JobTracker 监控所有 TaskTracker 与 Job 的健康状况，一旦发现失败，就将相应的任务转移到其他节点。JobTracker 会跟踪任务的执行进度、资源使用量等信息，并将这些信息告诉任务调度器（TaskScheduler），而调度器会在资源出现空闲时，选择合适的任务去使用这些资源。
-   **TaskTracker**：TaskTracker 会周期性地通过“心跳”将本节点上资源的使用情况和任务的运行进度汇报给 JobTracker，同时接收 JobTracker 发送过来的命令并执行相应的操作（如启动新任务、杀死任务等）。TaskTracker 使用“slot”等量划分本节点上的资源量（CPU、内存等）。一个 Task 获取到一个 slot 后才有机会运行，而 Hadoop 调度器的作用就是将各个 TaskTracker 上的空闲 slot 分配给 Task 使用。slot 分为 Map slot 和 Reduce slot 两种，分别供 MapTask 和 ReduceTask 使用。
-   **Task**：Task 分为 Map Task 和 Reduce Task 两种，均由 TaskTracker 启动。Map Task 将输入数据分割成多个小块，每个小块由一个 Map 任务处理。Map 任务将输入数据转换为键值对，并将这些键值对发送给 Reduce 任务。Map 任务通常使用哈希函数将键值对分配给不同的 Reduce 任务。Reduce 任务接收来自 Shuffle 阶段的键值对，并对这些键值对进行合并和计算。

#### 工作流程

MapReduce 模型的工作流程可以分为以下几个步骤：

1. **输入数据**：\
   输入数据被分割成多个数据块，每个数据块的大小通常为 64MB 到 128MB。这些数据块被存储在分布式文件系统中，如 HDFS。
2. **Split 阶段**：\
   Split 阶段将输入数据分割成多个小块，每个小块由一个 Map 任务处理。\
   HDFS 以固定大小的 block 为基本单位存储数据，而 MapReduce 处理单位是 split。\
   split 是一个逻辑概念，它只包含一些元数据信息，比如数据起始位置、数据长度、数据所在节点等。它的划分方法完全由用户自己决定。
3. **Map 阶段**：\
   Map 阶段将输入数据分割成多个小块，每个小块由一个 Map 任务处理。Map 任务将输入数据转换为键值对，并将这些键值对发送给 Reduce 任务。Map 任务通常使用哈希函数将键值对分配给不同的 Reduce 任务。\
   每个 Map 任务会被分配一个缓存，默认会设置 1000，并设置溢写比例为 0.8，当缓存达到 80%时，就会触发溢写操作，将数据写入磁盘。Map 阶段进行数据的排序、合并与归并，最终将数据写入磁盘。

    > Hadoop 为每个 split 创建一个 Map 任务，split 的多少决定了 Map 任务的数目。大多数情况下，理想的分片大小是一个 HDFS 块（默认 64MB）。

4. **Shuffle 阶段**：\
   Shuffle 阶段将 Map 任务输出的键值对按照键进行排序，并将相同键的键值对发送给同一个 Reduce 任务。Shuffle 阶段通常使用哈希函数将键值对分配给不同的 Reduce 任务。
5. **Reduce 阶段**：\
   Reduce 任务接收来自 Shuffle 阶段的键值对，并对这些键值对进行合并和计算。Reduce 任务通常使用哈希函数将键值对分配给不同的 Reduce 任务。\
   Reduce 通过 RPC 向 JobTracker 询问 MapTask 的输出结果，JobTracker 会告诉 ReduceTask 哪些机器存有相应的数据，然后 ReduceTask 通过 HTTP 方式从这些机器上获取数据。\
   获取数据后，ReduceTask 会对数据归并、合并、写入磁盘。数据很少会直接从缓存归并，并输出给 Reduce。

    > 最优的 Reduce 任务个数取决于集群中可用的 reduce 任务槽(slot)的数目——通常设置比 reduce 任务槽数目稍微小一些的 Reduce 任务个数（这样可以预留一些系统资源处理可能发生的错误）。

6. **输出数据**：\
   Reduce 任务将计算结果输出到分布式文件系统中，这些结果可以被其他应用程序读取和使用。

:::tip[概述]

-   不同的 Map 任务之间不会通信，它们各自独立地处理输入数据。
-   不同的 Reduce 任务之间也不会通信，它们各自独立地处理来自 Map 任务的输出数据。
-   用户不能显式地从一台机器向另一台机器发送消息，所有的数据交换都是通过 MapReduce 框架进行的。
    :::

#### 问题

-   JobTracker 是 MapReduce 的集中处理点，存在单点故障。
-   JobTracker 完成了太多的任务，造成了过多的资源消耗。
-   当 MapReduce job 非常多时，会造成很大的内存开销：业界总结 Hadoop 的 MapReduce 只能支持 4000 节点主机的上限。
-   在 TaskTracker 端，以 map/reduce task 的数目作为资源的表示过于简单，没有考虑到 cpu/内存的占用情况，如果两个大内存消耗的任务被调度到了一块，很容易出现溢出。

#### MapReduce on Yarn

YARN（Yet Another Resource Negotiator）是 Hadoop 2.x 引入的一个新的资源管理框架，它将资源管理和作业调度解耦，使得 MapReduce 可以与其他计算框架（如 Spark、Tez 等）共享集群资源。

-   设计优点

        -   这个设计大大减小了 JobTracker（也就是现在的 ResourceManager）的资源消耗，并且让监测每一个 Job 子任务 (tasks) 状态的程序分布式化了，更安全、更优美。
        -   另外，在新版中，ApplicationMaster 是一个可变更的部分，用户可以对不同的编程模型写自己的 ApplicationMaster，让更多类型的编程模型能够跑在 Hadoop 集群中。
        -   能够支持不同的编程模型。
        -   对于资源的表示以内存为单位（在目前版本的 Yarn 中，没有考虑 CPU 的占用），比之前以剩余 slot 数目更合理。
        -   既然资源表示成内存量，那就没有了之前的 mapslot/reduceslot 分开造成集群资源闲置的尴尬情况了。

## 负载均衡

---

### 概述

负载均衡（Load Balancing）是一种网络架构，它通过将网络流量分配到多个服务器来提高系统的可用性和性能。**负载均衡器**（Load Balancer）是用于实现负载均衡的设备或软件。负载均衡器分为**DNS 负载均衡**、**硬件负载均衡**和**软件负载均衡**三种类型。

负载均衡器通常位于网络中的关键位置，如防火墙、路由器或交换机等。它通过监听来自客户端的请求，并根据一定的算法将请求分配给后端的服务器。负载均衡器可以确保后端服务器能够均匀地处理请求，从而提高系统的整体性能和可用性。

### DNS 负载均衡

-   优点：实现简单，成本低；就近访问，提高访问速度。
-   缺点：
    -   DNS 解析结果可能存在缓存，导致负载不均衡；
    -   扩展性差，无法根据业务需求动态调整负载；
    -   分配策略比较简单，不能区分服务器差异，不能感知服务器状态。

### 硬件负载均衡

目前业界典型的硬件负载均衡设备有两款：F5 和 A10。

-   优点：

        -   功能强大，支持全面的负载均衡算法，支持全局负载均衡；
        -   性能强大，支持百万级并发；
        -   稳定性高；
        -   支持安全防护。

-   缺点：
    -   成本高，价格昂贵；
    -   扩展性差，无法满足业务快速变化的需求；
    -   维护成本高，需要专业人员进行维护。

### 软件负载均衡

软件负载均衡器通常运行在服务器上，通过软件实现负载均衡功能。常见的软件负载均衡器包括 Nginx、HAProxy、LVS 等。Nginx 是 7 层负载均衡器，HAProxy 是 4 层负载均衡器，LVS 是 4 层负载均衡器。

:::tip
层数的区别在于**协议**和**灵活性**。Nginx 支持 HTTP、E-mail 协议，而 LVS 和协议无关，几乎所有应用都可以支持。
:::

-   优点：简单、便宜、灵活；
-   缺点：与硬件负载均衡相比，性能较差，功能不够强大，一般不具备安全防护功能。

### 负载均衡典型架构

-   **地理级别负载均衡**：当用户访问的时候，根据用户地理位置，将用户请求分发到最近的服务器上，从而提高访问速度和用户体验。
-   **集群级别负载均衡**：F5 收到请求后，进行集群级别的负载均衡。
-   **机器级别负载均衡**：Nginx 收到用户请求后，将用户请求发送给集群里面的某台服务器。

### 负载均衡的算法

分配标准有以下几种：**任务数平分**、**负载均衡**、**性能最优**、**Hash**。

-   **任务数平分**：将任务均匀地分配给所有可用的服务器。
-   **负载均衡**：根据服务器的负载情况，将任务分配给负载较低的服务器。
-   **性能最优**：根据服务器的性能指标，将任务分配给性能最优的服务器。
-   **Hash**：根据请求的某个属性（如 IP 地址、URL 等）进行哈希运算，将任务分配给哈希值对应的服务器。

> 具体有哪些算法呢？

-   轮询（Round Robin）：将请求按顺序分配给服务器。
-   加权轮询（Weighted Round Robin）：根据服务器的权重，将请求按比例分配给服务器。
-   负载最低优先（Least Connections）：将请求分配给当前连接数最少的服务器。
-   性能最优（Best Performance）：将请求分配给响应时间最短的服务器。
-   IP Hash（IP Hash）：根据请求的 IP 地址进行哈希运算，将请求分配给哈希值对应的服务器。
-   URL Hash（URL Hash）：根据请求的 URL 进行哈希运算，将请求分配给哈希值对应的服务器。
-   ID Hash（ID Hash）：根据请求的 ID 进行哈希运算，将请求分配给哈希值对应的服务器。

## 消息队列

---

### 通信模型

-   基于寻址类型，可以分为直接通信和间接通信。
-   基于阻塞类型，可以分为同步通信和异步通信。
-   基于缓存类型，可以分为瞬态通信和持久化通信。
-   基于内容类型，可以分为事件通信、指令通信、数据通信和流通信。
-   基于确认类型，可以分为无确认通信、有确认通信和可靠通信。
-   基于接收节点数，可以分为点对点通信、多播通信、任播通信、广播通信和地域性群播通信。
-   基于通讯方向，可以分为单向通信和半双工通信和全双工通信。
-   基于发起方，可以分为 Pull 通信和 Push 通信。
-   基于消息存储，可以分为瞬态通信和持久化通信。

## 分布式服务框架

---

### 原理

-   Service 层主要包括 Java 动态代理，供消费者使用，主要用于将服务提供者的接口封装成远程服务调用，隐藏远程调用的细节，使得消费者调用远程服务就像调用本地服务一样；
-   Java 反射，服务提供者使用，根据消费者请求消息中的接口名、方法名、参数列表反射调用服务提供者的接口本地实现类。
-   业务的服务接口定义和实现类，对于使用 Spring 配置化开发的就是 Spring Bean，具体服务逻辑内容由业务部门实现，平台部门负责将业务接口发布成远程服务。

### 功能

从功能角度看，分布式服务框架通常包括两大功能：**服务治理中心**和**服务注册中心**。

-   服务注册中心：负责服务的发布和通知，通常支持对等集群的部署，某一个服务中心宕机并不会导致整个服务注册中心集群不可用。即便整个服务注册中心全部宕机，也只影响新服务的注册和发布，不影响已经发布服务的访问。HSF 使用的是基于数据库的 ConfigServer，Dubbo 使用的是 Zookeeper，Spring Cloud 使用的是 Eureka。
-   服务治理中心：通常包含服务治理接口和服务质量 Portal，架构师、测试人员和系统运维人员通过服务治理 Portal 对服务的运行状态、历史数据、健康度和调用关系等进行可视化的分析和维护，目标就是要持续化服务，防止服务架构腐化，保证服务高质量运行。

### 功能特性

1. 服务订阅发布

-   配置化发布和引用服务：支持通过 XML 配置的方法发布和导入服务，降低对业务代码的侵入；
-   服务自动发现机制：支持服务实时自动发现，由注册中心推送服务地址，消费者不需要配置服务提供者地址，服务地址透明化;
-   服务在线注册和去注册：支持运行注册新的服务，也支持运行态取消某个服务的注册。

2. 服务路由

-   路由策略：默认提供随机路由、轮询、基于权重的路由策略，避免每个框架使用者都重复开发；
-   粘滞连接：总是向同一个提供发发起请求，除非此提供方宕机再切换到另一台；
-   路由定制：支持用户自定义路由策略，扩展平台的功能。

3. 集群容错

-   Failover：失败自动切换，当出现失败重试其他服务器，通常用于读操作，也可以用于幂等性写操作；
-   Failback：失败自动恢复，后台记录失败请求，定时重试，用于消息通知操作；
-   Failfast：快速失败，只发起一次调用，失败立即报错，通常用于非幂等性写操作；

4. 服务调用

-   同步调用：消费者发起服务调用之后，同步阻塞等待服务端响应；
-   异步调用：消费者发起服务调用之后，不阻塞立即返回，由服务端返回应答后异步通知消费者；
-   并行调用：消费者同时对多个服务提供者批量发起服务调用请求，批量发起请求后集中等待应用。

5. 多协议

-   私有协议：支持二进制等私有协议，支持私有协议定制和扩展；
-   共有协议：提供 Web Service 等共有协议，用于外部服务对接。

6. 序列化方式

-   二进制类序列化：支持 Thrift、Protocol Buffer 等二进制协议，提升序列化性能；
-   文本类序列化：支持 JSON、XML 等文本协议，提升通用性和可读性。

7. 统一配置

-   本地静态配置：安装部署修改一次、运行态不修改，可以存放到本地配置文件；
-   基于配置中心的动态配置：运行态需要调整的参数，统一放到配置中心（服务注册中心），修改之后统一下发，实时生效。

### 对于幂等性的补充

**分布式系统中的幂等性概念**：用户对于同一操作发起的一次请求或多次请求的结果是一致的，不会因为多次点击而产生副作用。

**幂等性的重要性**：由于服务无状态的本质们对于业务的敏感性是很弱的。如果不支持幂等性，就会导致服务重复操作，对于业务数据进行违背业务逻辑的操作。比如，下单以后付款，如果不支持幂等性，可能会导致多次付款。

**幂等场景**：① 网络波动导致请求重复；② 分布式消息消费：任务发布后，使用分布式消息服务来进行消费；③ 用户重复操作：用户在操作时，可能无意触发多次交易，甚至没有响应而有意重复操作。④ 未关闭的重试机制：因开发、测试或运维人员未检测出错误的情况下开启了重试机制，导致重复操作。

幂等性的影响往往作用在数据上，而不同**数据库操作**对于幂等性的反应也不一样。

-   新增类请求：不具备幂等性；
-   查询类动作：重复查询不会产生或变更新的数据，查询具有天然幂等性；
-   更新类请求：① 基于主键的计算式更新，不具有幂等性；② 基于主键的赋值式更新，具有幂等性；③ 基于条件查询的更新，不一定具有幂等性。
-   删除类请求：基于主键的删除，具有幂等性。一般业务层面都是逻辑删除，而基于主键的逻辑删除操作也是具有幂等性的。

**数据库的幂等性解决方案**

-   数据库加锁法：让关键资源的操作串行器来，但是会引入效率、死锁问题；
-   全局唯一 ID 法：根据业务的操作和内容生成一个全局 ID，在执行操作前先判断 ID 是否存在，借此判断操作是否已经执行。该方案缺点是实现起来比较困难，同时与服务的业务解绑有一定的冲突；
-   去重表法：在本身具有唯一标识的业务场景下是非常好的方法，利用唯一的标识号来判断是否已经执行过操作；
-   多版本控制法：为每一次操作添加一次版本号以示区别。缺点在于版本号的管理，以及通常适用于更新操作，并且往往需要配合日志来完成数据最的一致性；
-   状态机控制法：这种方法是适合在有状态机流转的情况下，比如就会订单的创建和付款，订单的状态流转是有限的，可以通过状态机来控制幂等性。

### 微服务

#### 概述

-   **微服务**是一种架构设计模式。在微服务架构中，业务逻辑被拆分成一系列小而松散耦合的分布式组件，共同构成了较大的应用。每个组件都被称为微服务。
-   每个微服务都在整体架构中执行单独的任务，或者负责单独的功能。
-   每个微服务可能会被一个或多个其他微服务调用，以执行较大应用需要完成的具体任务。
-   系统为任务执行——比如搜索或显示图片任务，或者其他可能需要多次执行的任务提供了统一的解决处理方式，并限制应用内不同地方生成或维护相同功能的多个版本。
-   微服务是围绕业务功能构建的，可以通过全自动部署机制进行独立部署。这些服务的集中化管理已经是最少的，他们可以用不同的编程语言编写，并使用不同的数据存储技术。
-   微服务需要做到**负责单功能**、**单独部署**、**包含一个或多个进程**、**拥有自己的数据存储**、**一只小团队就能维护几个微服务**、**可替换的**。

#### 和 SOA 架构的区别

| 特性     | SOA                  | 微服务                       |
| -------- | -------------------- | ---------------------------- |
| 组件大小 | 大块业务逻辑         | 单独任务或小块业务逻辑       |
| 耦合     | 通常松耦合           | 总是松耦合                   |
| 公司架构 | 任何类型             | 小型、专注于功能交叉团队     |
| 管理     | 着重中央管理         | 着重分散管理                 |
| 目标     | 确保应用能够交互操作 | 执行新功能、快速拓展开发团队 |

#### 服务架构的服务集成

-   SOA 体系下，服务之间通过企业服务总线通信，许多业务逻辑在中间层（消息的路由、转换和组织）中实现；
-   微服务架构倾向于降低中心消息总线的依赖，将业务逻辑分布在每个具体的服务端；
-   大部分微服务基于 HTTP、JSON 这样的标准协议，集成不同的标准和格式变得不再重要。另外一个选择是采用轻量级的消息总线或者网关，有路由功能，没有复杂的业务逻辑。
-   **点对点方式**：直接调用服务，每个服务都开放 REST API，并且调用其他微服务的接口。在比较简单的微服务应用场景下，这种方式还可行，随着应用复杂度的提升，会变得越来越不可维护。此时，尽量不采用点对点的集成方式。
-   **API 网关方式**：其核心要点是，所有的客户端和消费端都通过统一的网关接入微服务，在网关层处理所有的非业务功能。通常，网管也是提供 REST/HTTP 的访问 API。服务端通过 API-GW 注册和管理服务。**优势在于**——① 有能力为微服务接口提供给网关层次的抽象；② 轻量的消息路由、格式转换；③ 统一控制安全、监控、限流等非业务功能。④ 每个微服务会变得更加轻量，非业务功能都在网关层统一处理，微服务只需要关注业务逻辑。
-   **消息代理方式**：微服务也可以集成在异步场景下，通过队列和订阅主题，实现消息的发布和订阅。一个微服务可以是消息的发布者，把消息通过异步的方式发送到队列或者订阅主题下，作为消费者的微服务可以从队列或者主题获取消息。通过消息中间件把之间的直接调用解耦。通常异步的生产者/消费者模式，通过 AMQP、MQTT、Kafka 等消息中间件实现。

#### 微服务架构的服务发现

-   **客户端发现模式**：客户端直接调用服务，客户端负责发现服务的位置。优点是简单直接的同时，因为知晓可用的服务实例，能针对特定应用实现智能负载均衡；缺点是客户端需要实现服务发现的逻辑，服务发现的逻辑分散在客户端，不利于统一管理。
-   **服务端发现模式**：客户端通过服务注册中心查询服务实例的位置，服务注册中心负责维护服务实例的元数据。服务端发现模式将服务发现的逻辑集中管理，客户端只需要知道服务注册中心的地址，就可以实现服务发现。服务端发现模式有如下优点：① 服务注册中心统一管理服务实例，便于集中管理；② 客户端只需要知道服务注册中心的地址，就可以实现服务发现，客户端不需要实现服务发现的逻辑；缺点是，有的部署环境会免费提供这一功能，但是如果不然，就需要额外的开销——负载均衡器。

#### 微服务架构的服务注册

-   服务注册表是服务发现的核心部分，是包含服务实例的网络地址的数据库。
-   服务注册表需要高可用而且随时更新。客户端能够缓存从服务注册表中获取的网络地址，然而，这些信息最终会过时，客户端也就无法发现服务实例。因此，服务注册表会包含若干服务端，使用复制协议保持一致性。
-   服务实例必须在注册表中注册和注销。注册和住下有两种不同的方法：自注册模式和第三方注册模式。

#### 微服务架构的数据去中心化

-   每个微服务有自己私有的数据库持久化业务逻辑；
-   每个微服务只能访问自己的数据库；
-   某些业务场景下，需要在一个事务中更新多个数据库。不能直接访问其他数据库，而是通过微服务操作。

### Docker

Docker 部分参考：[Docker](/docker/preview)
